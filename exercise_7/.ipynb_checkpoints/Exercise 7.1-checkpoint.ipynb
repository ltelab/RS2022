{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Fourier Transforms and Wavelet Transforms\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "\n",
    "In this exercise we will study two very versatile and useful transforms and see some examples of their uses in remote sensing using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this jupyter notebook\n",
    "\n",
    "The jupyter notebook is composed by a series of *cells*, each one containing either Python code or text instruction.\n",
    "The text instruction that you are currently reading here are inside a text cell.\n",
    "\n",
    "To run a cell, just click on it and then press the *Run* button at the top of the screen, or use the shortcut *Shift - Enter*.\n",
    "You will not need to run *text cells*.\n",
    "Only cells containing Python code need to be run, making sure that you are following a descending order: from the beginning of this jupyter notebook to its end. \n",
    "Since this Jupyter notebook runs online, you will not need to install anything on your personal computer.\n",
    "\n",
    "If you prefer, and if you already have a Python installation, you can also download on your personal computer the notebook and the data from [here](https://github.com/alfonso-ferrone/exercise_7) and run it locally.\n",
    "In this case, you will need to install the packages listed in *requirements.txt*, available in the same GitHub repository linked above.\n",
    "\n",
    "You are not required to have pregressed Python knowledge.\n",
    "All you will have to do is to modify the value of some quantities (or *variables*) to achieve the result requested by each section of the exercise.\n",
    "You will need to interpret these results to answer the questions of the exercise.\n",
    "However, if you want to experiment with the code provided, feel free to edit the code: the change that you make will not overwrite the original copy of the notebook.\n",
    "Refreshing the exercise link will bring you back to a pristine copy of the exercise code, so, don't worry too much about the risk of \"breaking\" the code.\n",
    "\n",
    "Variables that will need to be modified will be preceeded by a comment, which clearly marks them as \"to modify\".\n",
    "A comment is a line of code preceeded by the symbol *#*.\n",
    "For example:\n",
    "\n",
    "    # This is a comment\n",
    "\n",
    "A variable that you will be required to modify will look like the following example:\n",
    "    \n",
    "    # Modify the value of the following variable\n",
    "    VARAIBLE_TO_MODIFY = 2\n",
    "\n",
    "Naturally, in each case the name of the variable will be different.\n",
    "To highlight those variables, they will always be written in UPPERCASE.\n",
    "\n",
    "To modify the variable, change the value after the = sign. For example:\n",
    "\n",
    "    VARAIBLE_TO_MODIFY = 3\n",
    "\n",
    "will change the value of *VARAIBLE_TO_MODIFY* from *2* to *3*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the exercise by running the next cell: it will import the libraries needed for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np               # Array manipulation\n",
    "import PIL.Image                 # Manipulation of images\n",
    "import matplotlib.pyplot as plt  # Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 2D Fourier transform\n",
    "\n",
    "The Fourier transform decomposes a signal into its main constituting frequencies and besides the rich additional information it gives about the signal, it is also a very convenient tool for signal filtering and processing.\n",
    "This section shows some properties of the 2D Fourier transform as well as some examples of usage for remote sensing data, in particular satellite images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Study of the 2D Fourier transform\n",
    "\n",
    "In this exercice we will study the Fourier transform of an aerial image of Grammichele, in Sicily.\n",
    "We will then observe the effects of rotation and translation on the frequency spectrum.\n",
    "\n",
    "Let's start by loading the image. Run the following cells: there is no need to modify anything for the moment, the code will already load and display the image for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image\n",
    "grammichele = np.array(PIL.Image.open(\"1_Fourier/grammichele.tif\"))\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Computing x and y coordinates in meters\n",
    "dim_x = grammichele.shape[1]\n",
    "dim_y = grammichele.shape[0]\n",
    "new_x = np.arange(0, dim_x) * pix_res\n",
    "new_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Displaying the image\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.set_aspect('equal')\n",
    "mappable = ax.pcolormesh(new_x, new_y, grammichele, cmap='gray', shading='auto')\n",
    "ax.invert_yaxis()\n",
    "plt.sca(ax)\n",
    "plt.colorbar(mappable=mappable, label='Pixel Intensity')\n",
    "ax.set_xlabel('Distance [m]')\n",
    "ax.set_ylabel('Distance [m]')\n",
    "ax.set_title('Grammichele')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to perform the Fourier transform of the image just loaded and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the Fourier transform\n",
    "grammichele_fft = np.fft.fft2(grammichele)\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Shifting the zero-frequency component to the center of the spectrum\n",
    "grammichele_fft_centered = np.fft.fftshift(grammichele_fft)\n",
    "dim_x = grammichele_fft_centered.shape[1]\n",
    "dim_y = grammichele_fft_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "grammichele_fft_centered_real = np.absolute(grammichele_fft_centered)\n",
    "\n",
    "# Displaying the transform\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax.pcolormesh(new_x, new_y, grammichele_fft_centered_real, cmap='magma_r',\n",
    "                         vmin=0, vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax.set_xlabel('Frequency [1/m]')\n",
    "ax.set_ylabel('Frequency [1/m]')\n",
    "ax.set_title('Grammichele')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at both the original aerial image and its Fourier transform, you will be able to answer the first question of the exercise.\n",
    "\n",
    "\n",
    "> **Question 1**: What are the axis with the dominant frequencies? To which features do they correspond in the image?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we will load a copy of the original image, resized and translated.\n",
    "Run it to perform its Fourier transform and visualize the results side by side with the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image\n",
    "grammichele_translated = np.array(PIL.Image.open(\"1_Fourier/grammichele_scaled_translated.tif\"))\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Performing the Fourier transform\n",
    "grammichele_translated_fft = np.fft.fft2(grammichele_translated)\n",
    "\n",
    "# Shifting the zero-frequency component to the center of the spectrum\n",
    "grammichele_translated_fft_centered = np.fft.fftshift(grammichele_translated_fft)\n",
    "dim_x = grammichele_translated_fft_centered.shape[1]\n",
    "dim_y = grammichele_translated_fft_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "grammichele_translated_fft_centered_real = np.absolute(grammichele_translated_fft_centered)\n",
    "\n",
    "# Plotting the results and the aerial image\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "mappable0 = ax0.imshow(grammichele_translated, cmap='gray')\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Num. pixels - vertical')\n",
    "ax0.set_ylabel('Num. pixels - horizontal')\n",
    "ax0.set_title('Resized + Translated')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, grammichele_translated_fft_centered_real, cmap='magma_r',\n",
    "                         vmin=0., vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the operation once again for an image that has also been rotated of 20° (other than being resized and translated).\n",
    "Run the following cell to perform its Fourier transform and visualize the results side by side with the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image\n",
    "grammichele_rotated = np.array(PIL.Image.open(\"1_Fourier/grammichele_rotated_20.tif\"))\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Performing the Fourier transform\n",
    "grammichele_rotated_fft = np.fft.fft2(grammichele_rotated)\n",
    "\n",
    "# Shifting the zero-frequency component to the center of the spectrum\n",
    "grammichele_rotated_fft_centered = np.fft.fftshift(grammichele_rotated_fft)\n",
    "dim_x = grammichele_rotated_fft_centered.shape[1]\n",
    "dim_y = grammichele_rotated_fft_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "grammichele_rotated_fft_centered_real = np.absolute(grammichele_rotated_fft_centered)\n",
    "\n",
    "# Plotting the results and the aerial image\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "mappable0 = ax0.imshow(grammichele_rotated, cmap='gray')\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Num. pixels - vertical')\n",
    "ax0.set_ylabel('Num. pixels - horizontal')\n",
    "ax0.set_title('Resized + translated + rotated')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, grammichele_rotated_fft_centered_real, cmap='magma_r',\n",
    "                         vmin=0, vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Fourier transfor of:\n",
    "- the original image\n",
    "- the resized and translated image\n",
    "- the rotated (and resized+translated) image\n",
    "\n",
    "Compare the result and answer the following question.\n",
    "\n",
    "\n",
    "> **Question 2**: Do the rotation affect the Fourier transform differently from the sole translation+resizing? Explain how each of them differ from the Fourier transform of the original aerial image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Filtering in the frequency domain\n",
    "\n",
    "In this exercise we will see how to perform a simple filtering operation on the Fourier transform.\n",
    "\n",
    "We will perform the filtering on the Fourier transform results of the *grammichele.tif* image, obtained in Subsection 1.1.\n",
    "\n",
    "First of all, we will define a simple function to perform the filtering.\n",
    "This function takes the following arguments:\n",
    "- **im_fft**, the Fourier transform of the image that we want to filter. The zero frequency must be at the center;\n",
    "- **filter_type**, the type of filter, which can be either “lowpass” or “highpass”;\n",
    "- **cut_freq**, the cutting frequency, which is specified in [1/m];\n",
    "- **pix_res**, the pixel resolution in [m] (default 0.4 m).\n",
    "\n",
    "Since the resolution of the image is approximately 0.4 meters, a frequency of 1/2 [1/m] corresponds to a frequency of 1 every 5 pixels for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_filter(im_fft, filter_type, cut_freq, pix_res=0.4):\n",
    "    '''\n",
    "    Simple filtering on the Fourier transform.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    im_fft : complex numpy array (2D)\n",
    "        The Fourier transform of the image to filter.\n",
    "    filter_type : string\n",
    "        Type of filter, “lowpass” or “highpass”\n",
    "    cut_freq : float\n",
    "        Cutting frequency in [1/m]\n",
    "    pix_res : float\n",
    "        Pixel resolution in [m]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    im_filt : complex numpy array (2D)\n",
    "        The filtered image (complex array). Compute the absolute value before visualizing.\n",
    "    filt_fft : complex numpy array (2D)\n",
    "        The masked Fourier transform used to perform the filtering\n",
    "    '''\n",
    "    dim_x = im_fft.shape[1]\n",
    "    dim_y = im_fft.shape[0]\n",
    "\n",
    "    # Let' work with the 0 frequency at the center of the image\n",
    "    new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "    new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "    \n",
    "    x2d, y2d = np.meshgrid(new_x, new_y)\n",
    "    freq = np.sqrt(np.square(x2d) + np.square(y2d))\n",
    "    \n",
    "    if filter_type == 'lowpass':\n",
    "        freq_mask = freq < cut_freq\n",
    "    elif filter_type == 'highpass':\n",
    "        freq_mask = freq > cut_freq\n",
    "    else:\n",
    "        # In case of invalid input\n",
    "        print('ERROR: Invalid parameter for filter type.')\n",
    "        empty_return = np.full(im_fft.shape, np.nan)\n",
    "        return empty_return, im_fft\n",
    "    \n",
    "    # The frequency masked\n",
    "    filt_fft = np.multiply(im_fft, freq_mask)\n",
    "    \n",
    "    # Inverse Fourier transform\n",
    "    im_filt_complex = np.fft.ifft2(np.fft.ifftshift(filt_fft))\n",
    "    \n",
    "    return im_filt_complex, filt_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first have a look at the effect of a low-pass filter on the original Grammichele aerial image.\n",
    "To do so, we have to apply the function defined in the previous cell to the Fourier transform of the image, *grammichele_fft*, which we computed at the beginning of Subsection 1.1.\n",
    "\n",
    "It will be interesting to observe what effect changing the cutting frequency will have on the filtered image.\n",
    "\n",
    "**Here you will have to modify for the first time the value of a variable**\n",
    "\n",
    "Run the following cell a first time as it is, to visualize the results, and then change the value of the variable:\\\n",
    "*CUTTING_FREQUENCY*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following variable, containing the cutting frequency in [1/m]\n",
    "CUTTING_FREQUENCY = 0.27\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Filtering the image\n",
    "grammichele_lowpass, grammichele_lowpass_filt = fft_filter(grammichele_fft, 'lowpass', CUTTING_FREQUENCY, 0.4)\n",
    "\n",
    "# Shifting the zero-frequency component of the masked FFT to the center of the spectrum\n",
    "grammichele_lowpass_filt_centered = np.fft.fftshift(grammichele_lowpass_filt)\n",
    "dim_x = grammichele_lowpass_filt_centered.shape[1]\n",
    "dim_y = grammichele_lowpass_filt_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "grammichele_lowpass_filt_centered_real = np.absolute(grammichele_lowpass_filt_centered)\n",
    "\n",
    "# The x and y axis for the plot of the filtered image\n",
    "filt_x = np.arange(0, dim_x) * pix_res\n",
    "filt_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Displaying the results\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.set_aspect('equal')\n",
    "mappable = ax0.pcolormesh(filt_x, filt_y, np.absolute(grammichele_lowpass), cmap='gray', shading='auto')\n",
    "ax0.invert_yaxis()\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Distance [m]')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "ax0.set_title('Grammichele - low pass filter')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, grammichele_lowpass_filt_centered_real, cmap='magma_r',\n",
    "                         vmin=0., vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modifying the value of CUTTING_FREQUENCY in the previous cell, you can observe the effects of more and less restrictive low-pass filters on the image.\n",
    "You are now ready to answer the next question of the exercise:\n",
    "\n",
    "> **Question 3**: What is the effect of a low-pass filter on the image? What effect do the modification of CUTTING_FREQUENCY have on the final result?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the high-pass filter to the image.\n",
    "The procedure follows closely the one used for the low-pass filter.\n",
    "\n",
    "Like before, run the following cell a first time as it is, to visualize the results, and then change the value of the variable:\\\n",
    "*CUTTING_FREQUENCY*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Change the following variable, containing the cutting frequency in [1/m]\n",
    "CUTTING_FREQUENCY = 0.27\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Filtering the image\n",
    "grammichele_highpass, grammichele_highpass_filt = fft_filter(grammichele_fft, 'highpass', CUTTING_FREQUENCY, 0.4)\n",
    "\n",
    "# Shifting the zero-frequency component of the masked FFT to the center of the spectrum\n",
    "grammichele_highpass_filt_centered = np.fft.fftshift(grammichele_highpass_filt)\n",
    "dim_x = grammichele_highpass_filt_centered.shape[1]\n",
    "dim_y = grammichele_highpass_filt_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "grammichele_highpass_filt_centered_real = np.absolute(grammichele_highpass_filt_centered)\n",
    "\n",
    "# The x and y axis for the plot of the filtered image\n",
    "filt_x = np.arange(0, dim_x) * pix_res\n",
    "filt_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Displaying the results\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.set_aspect('equal')\n",
    "mappable = ax0.pcolormesh(filt_x, filt_y, np.absolute(grammichele_highpass), cmap='gray', shading='auto')\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Distance [m]')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "ax0.set_title('Grammichele - high pass filter')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, grammichele_highpass_filt_centered_real, cmap='magma_r',\n",
    "                         vmin=0., vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the low-pass case, by modifying the value of CUTTING_FREQUENCY in the previous cell you can observe the effects of more and less restrictive high-pass filters on the image.\n",
    "\n",
    "> **Question 4**: What is the effect of a high-pass filter on the image? What effect do the modification of CUTTING_FREQUENCY have on the final result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will sum the images obtained from the low-pass and high-pass filters, with the same cutting frequency, in the previous two code cells.\n",
    "\n",
    "**Attention**: Remember to run again the cell setting the same cutting frequency (variable: *CUTTING_FREQUENCY*) before running the next cell!\n",
    "\n",
    "The result will be visualized side by side with the original Grammichele image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing low-pass and high-pass filter results\n",
    "grammichele_filter_sum = grammichele_lowpass + grammichele_highpass\n",
    "\n",
    "# Displaying the results\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.set_aspect('equal')\n",
    "mappable = ax0.pcolormesh(filt_x, filt_y, grammichele, cmap='gray', shading='auto')\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Distance [m]')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "ax0.set_title('Grammichele - original')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "mappable1 = ax1.pcolormesh(filt_x, filt_y, np.absolute(grammichele_filter_sum), cmap='gray', shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable1, label='Pixel Intensity')\n",
    "ax1.set_xlabel('Distance [m]')\n",
    "ax1.set_ylabel('Distance [m]')\n",
    "ax1.set_title('Low-pass + high-pass filter results')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually compare the original image and the one obtained from the sum of the low-pass and high-pass filter result.\n",
    "\n",
    "> **Question 5**: What do you observe? If you look closely at the code, you will notice that we first summed the filtered images as *complex number*, and then took the *absolute value* of the result before displaying the image. Would we have obtained the same result if we summed directly the *absolute value* of the two filtered images? Explain the reasoning behind your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Stripes on a Landsat image\n",
    "\n",
    "On May 31, 2003 the Scan Line Corrector (SLC) in the Landsat 7 ETM+ instrument failed.\n",
    "The SLC consists of a pair of small mirrors that rotate about an axis in tandem with the motion of the main ETM+ scan mirror. The purpose of the SLC is to compensate for the forward motion (along-track) of the spacecraft so that the resulting scans are aligned parallel to each other.\n",
    "Without the effects of the SLC, the instrument images the Earth in a ”zig-zag”.\n",
    "A consequence is that the scanned image is contaminated with black stripes.\n",
    "\n",
    "We will now visualize an example of Landsat image affected by this issue.\n",
    "The product chosen is the \"LandsatLook Natural Color Image\".\n",
    "The image has been cropped to reduce its size and allow a faster manipulation on the online version of this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image\n",
    "landsat7_all = np.array(PIL.Image.open(\"1_Fourier/landsat7.jpg\"))\n",
    "\n",
    "# Printing at screen the size of the image\n",
    "print('Size of the image: ', landsat7_all.shape)\n",
    "\n",
    "# Displaying the image\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "mappable = ax.imshow(landsat7_all)\n",
    "ax.set_xlabel('Num. pixels [-]')\n",
    "ax.set_ylabel('Num. pixels [-]')\n",
    "ax.set_title('Landsat 7 - LandsatLook Natural Color Image - 01/04/2004 19:50')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the following analysis, we will focus now only on the firts component of the array in which the image is stored (the \"red\" channel).\n",
    "\n",
    "Repeating the procedure used in the previous sections on the aerial image of Grammichele, we will compute the Fourier transform for the first component of the Landsat 7 image.\n",
    "The computation may require more time than in the Grammichele case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image\n",
    "landsat7 = landsat7_all[:,:,0]\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 30. # m\n",
    "\n",
    "# Performing the Fourier transform\n",
    "landsat7_fft = np.fft.fft2(landsat7)\n",
    "\n",
    "# Shifting the zero-frequency component to the center of the spectrum\n",
    "landsat7_fft_centered = np.fft.fftshift(landsat7_fft)\n",
    "dim_x = landsat7_fft_centered.shape[1]\n",
    "dim_y = landsat7_fft_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The x and y axis for the plot of the original Landsat7 image\n",
    "orig_x = np.arange(0, dim_x) * pix_res\n",
    "orig_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# The absolute value of the array\n",
    "landsat7_fft_centered_real = np.absolute(landsat7_fft_centered)\n",
    "\n",
    "# Plotting the results and the Landsat image\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.set_aspect('equal')\n",
    "# The image is rotated to have a nicer visualization\n",
    "mappable0 = ax0.pcolormesh(orig_y/1000., orig_x/1000., landsat7.T, cmap='gray', shading='auto')\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Distance [km]')\n",
    "ax0.set_ylabel('Distance [km]')\n",
    "ax0.set_title('')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 5.e5 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, landsat7_fft_centered_real, cmap='magma_r',\n",
    "                         vmin=0., vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the original image and the magnitude of the Fourier transform.\n",
    "\n",
    "> **Question 6**: Where do you see the signature of the stripes on the spectrum? Give an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a function, *pie_slice_filter*, that filters the 2D Fourier transform of the original image.\n",
    "Like the simple low-pass and high-pass filters of Subsection 1.2, this function will take multiple arguments as input:\n",
    "- **im_fft**, the Fourier transform of the image that we want to filter. The zero frequency must be at the center.;\n",
    "- **angle_center**, the direction in which we will filter the Fourier transform. Must be between -180° and 180°;\n",
    "- **angle_width**, the width in degrees of the slice that we will filter out;\n",
    "- **min_freq**, the minimal frequency that is affected by the filter in [1/m];\n",
    "- **pix_res**, the pixel resolution in [m] (default 30.0 m, like Landsat 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_slice_filter(im_fft, angle_center, angle_width, min_freq, pix_res=30.):\n",
    "    '''\n",
    "    Filtering specific angles of the Fourier transform.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    im_fft : complex numpy array (2D)\n",
    "        The Fourier transform of the image to filter. The zero frequency must be at the center.\n",
    "    angle_center : float\n",
    "        The direction in which we will filter the Fourier transform.\n",
    "    angle_width : float\n",
    "        The width in degrees of the slice that we will filter out;\n",
    "    min_freq : float\n",
    "        The minimal frequency that is affected by the filter [1/m]\n",
    "    pix_res : float\n",
    "        Pixel resolution in [m]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    im_filt : complex numpy array (2D)\n",
    "        The filtered image (complex array). Compute the absolute value before visualizing.\n",
    "    filt_fft : complex numpy array (2D)\n",
    "        The masked Fourier transform used to perform the filtering\n",
    "    '''\n",
    "    # Checking the validity of the angles (does not work for angles out of [-360, 360])\n",
    "    if angle_center > 180.:\n",
    "        angle_center -= 180\n",
    "    elif angle_center < -180.:\n",
    "        angle_center += 180\n",
    "    \n",
    "    # The image dimensions\n",
    "    dim_x = im_fft.shape[1]\n",
    "    dim_y = im_fft.shape[0]\n",
    "\n",
    "    # Let' work with the 0 frequency at the center of the image\n",
    "    new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "    new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "    \n",
    "    x2d, y2d = np.meshgrid(new_x, new_y)\n",
    "    freq = np.sqrt(np.square(x2d) + np.square(y2d))\n",
    "    \n",
    "    # Computing the angle for each direction in the image matrix\n",
    "    img_angles = np.degrees(np.arctan2(x2d, y2d))\n",
    "\n",
    "    # Creating the mask\n",
    "    freq_mask = np.ones(im_fft.shape, dtype='bool')\n",
    "    # 1) Condition on the angles\n",
    "    # Direction 1\n",
    "    min_freq_1 = angle_center - angle_width/2.\n",
    "    max_freq_1 = angle_center + angle_width/2.\n",
    "\n",
    "    cond_1 = np.logical_and(img_angles > min_freq_1, img_angles < max_freq_1)\n",
    "    if min_freq_1 < -180.:\n",
    "        cond_1 = np.logical_or(cond_1, img_angles > min_freq_1+360.)\n",
    "    if max_freq_1 > 180.:\n",
    "        cond_1 = np.logical_or(cond_1, img_angles < max_freq_1-360.)\n",
    "\n",
    "    # Direction 1 + 180\n",
    "    if angle_center > 0.:\n",
    "        center2 = angle_center - 180.\n",
    "    else:\n",
    "        center2 = angle_center + 180.\n",
    "    \n",
    "    min_freq_2 = center2 - angle_width/2.\n",
    "    max_freq_2 = center2 + angle_width/2.\n",
    "    \n",
    "    cond_2 = np.logical_and(img_angles > min_freq_2, img_angles < max_freq_2)\n",
    "    if min_freq_2 < -180.:\n",
    "        cond_2 = np.logical_or(cond_2, img_angles > min_freq_2+360.)\n",
    "    if max_freq_2 > 180.:\n",
    "        cond_2 = np.logical_or(cond_2, img_angles < max_freq_2-360.)\n",
    "\n",
    "    cond = np.logical_or(cond_1, cond_2)\n",
    "    freq_mask[cond] = False\n",
    "\n",
    "    # 2) Condition on the minimum frequency\n",
    "    freq_mask[freq < min_freq] = True\n",
    "    \n",
    "    # The frequency masked\n",
    "    filt_fft = np.multiply(im_fft, freq_mask)\n",
    "    \n",
    "    # Inverse Fourier transform\n",
    "    im_filt_complex = np.fft.ifft2(np.fft.ifftshift(filt_fft))\n",
    "    \n",
    "    return im_filt_complex, filt_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 0° position of **angle_center** is arbitraryy, we decided to set it along the positive section of the vertical axis. Angles clockwise from there will be positive (0° -> 180°), and angles counterclockwise from there will be negative.\n",
    "\n",
    "If the explanation above is not clear enough, we wrote the following cell to displays the values of the angles on a matrix created ad hoc.\n",
    "Run it to visualize which angle has been assigned to the directions in an arbitrary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generating the coordinate matrices\n",
    "a = np.arange(-20, 20)\n",
    "b = np.arange(-20, 20)\n",
    "aa, bb = np.meshgrid(a,b)\n",
    "\n",
    "# Plotting the angles\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.set_aspect('equal')\n",
    "mappable = ax.pcolormesh(np.degrees(np.arctan2(aa, bb)), cmap='RdYlGn')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.sca(ax)\n",
    "plt.colorbar(mappable=mappable, label='Angle value [degree]')\n",
    "ax.set_title('Explanation of the angle values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply the *pie_slice_filter* function on the same Lansat7 band that we used for computing the Fourier transform displayed few cells above.\n",
    "\n",
    "We provide already the code to perform the filtering, but the parameters that we have set are not optimal.\n",
    "Run first the cell as it is, and look at what our sub-optimal parameters produce.\n",
    "The visualization of the result is already coded in the cell.\n",
    "\n",
    "After visualizing the results, you can start to modify the parameters of the filtering.\n",
    "\n",
    "**You will have to modify three variables in the next cell**:\n",
    "- ANGLE_CENTER\n",
    "- ANGLE_WIDTH\n",
    "- MIN_FREQ\n",
    "\n",
    "Choose the values that you think work best in our case.\n",
    "Feel free to change the values radically, but remember to remain within the function constraints:\n",
    "- ANGLE_CENTER between -180° and 180°\n",
    "- ANGLE_WIDTH < 180°\n",
    "- MIN_FREQ within the frequency span of the Fourier transform (look at the range of the axis).\n",
    "\n",
    "The aim is the reconstruction of the image and the elimination (as much as possible) of the black stripes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# The three variables to modify\n",
    "ANGLE_CENTER = 0.0\n",
    "ANGLE_WIDTH = 20.0\n",
    "MIN_FREQ = 1\n",
    "# -----------------------------\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 30 # mand\n",
    "\n",
    "# Filtering the image\n",
    "landsat7_pie_slice, landsat7_pie_slice_filt_centered = pie_slice_filter(landsat7_fft_centered,\n",
    "                                                                        ANGLE_CENTER,\n",
    "                                                                        ANGLE_WIDTH,\n",
    "                                                                        MIN_FREQ,\n",
    "                                                                        pix_res)\n",
    "\n",
    "# Shifting the zero-frequency component of the masked FFT to the center of the spectrum\n",
    "# landsat7_pie_slice_filt_centered = np.fft.fftshift(landsat7_pie_slice_filt)\n",
    "dim_x = landsat7_pie_slice_filt_centered.shape[1]\n",
    "dim_y = landsat7_pie_slice_filt_centered.shape[0]\n",
    "new_x = np.arange(-np.floor(dim_x/2.), np.floor(dim_x/2.)) * pix_res / dim_x\n",
    "new_y = np.arange(-np.floor(dim_y/2.), np.floor(dim_y/2.)) * pix_res / dim_y\n",
    "\n",
    "# The absolute value of the array\n",
    "landsat7_pie_slice_filt_centered_real = np.absolute(landsat7_pie_slice_filt_centered)\n",
    "\n",
    "# The x and y axis for the plot of the filtered image\n",
    "filt_x = np.arange(0, dim_x) * pix_res\n",
    "filt_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Displaying the results (in 2 images this time, to have them  bigger)\n",
    "fig, axes = plt.subplots(1,1,figsize=(14,6))\n",
    "\n",
    "ax0 = axes\n",
    "ax0.set_aspect('equal')\n",
    "mappable = ax0.pcolormesh(filt_x/1000., filt_y/1000., np.absolute(landsat7_pie_slice),\n",
    "                          cmap='gray', shading='auto')\n",
    "ax0.invert_yaxis()\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable0, label='Pixel Intensity')\n",
    "ax0.set_xlabel('Distance [Km]')\n",
    "ax0.set_ylabel('Distance [Km]')\n",
    "ax0.set_title('Landsat7 - after filtering')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, axes = plt.subplots(1,1,figsize=(7,5.5))\n",
    "ax1 = axes\n",
    "ax1.set_aspect('equal')\n",
    "colorbar_limit = 1.e6 # This parameters limits the extent of the colorbar\n",
    "mappable = ax1.pcolormesh(new_x, new_y, landsat7_pie_slice_filt_centered_real, cmap='magma_r',\n",
    "                         vmin=0., vmax=colorbar_limit, shading='auto')\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Absolute value of the Fourier Transform')\n",
    "ax1.set_xlabel('Frequency [1/m]')\n",
    "ax1.set_ylabel('Frequency [1/m]')\n",
    "ax1.set_title('Filtered Fourier transform')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After investigating the effect of changing the three variables in the prevous cell, you are ready to reply to the next question of the exercise.\n",
    "\n",
    "> **Question 7**: What are, in your opinion, the best values for the three parameters (ANGLE_CENTER, ANGLE_WIDTH, MIN_FREQ)? Explain the reasoning behind your choice.\n",
    "\n",
    "> **Question 8**: Even with the \"optimal\" set of values, the result is quite far from \"perfect\". What issues do you see? What areas are problematic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now at the end of the first part of the exercise.\n",
    "Let's clear up the workspace: run the next cell to remove all variables, and re-load the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are now moving to the wavelet part, let's clear up the workspace.\n",
    "%reset -sf\n",
    "\n",
    "# We have to re-load the needed libraries\n",
    "import numpy as np               # Array manipulation\n",
    "import scipy                     # Scientific computing\n",
    "import PIL.Image                 # Manipulation of images\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import pywt                      # Wavelets\n",
    "import skimage.restoration       # Wavelets denoising\n",
    "\n",
    "# For the 2D wavelet transform we will load directly the needed functions\n",
    "from pywt._doc_utils import wavedec2_keys, draw_2d_wp_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wavelet transforms\n",
    "\n",
    "In this section we want to illustrate some uses of the discrete wavelet transforms for remote sensing data in particular satellite images.\n",
    "We will use data from the [orthophoto mosaic SWISSIMAGE 10 cm](https://www.swisstopo.admin.ch/en/geodata/images/ortho/swissimage10.html).\n",
    "We decided to use an aerial image of the \"Banane\" (Unithèque).\n",
    "\n",
    "The wavelet transform provides a way for analyzing signals both in frequency and time (or space for images), which unlike the Fourier transform makes them useful for analyzing both local and global features of the signal.\n",
    "Wavelet transforms are stored more efficiently than Fourier transform opening new possibilities for signal compression.\n",
    "\n",
    "In this exercice we will focus on the discrete wavelet transform.\n",
    "This transforms employs two sets of functions, called scaling functions and wavelet functions, which are associated with low pass and highpass filters, respectively.\n",
    "The decomposition of the signal into different frequency bands is simply obtained by successive highpass and lowpass filtering of the original signal.\n",
    "The low-pass coefficients are called approximation coefficients and the high-pass coefficients are called details coefficients.\n",
    "\n",
    "We will visualize an example in the next code cell: a two-level transform of 1D signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the signal\n",
    "signal = np.load(\"2_Wavelets/signal.npy\")\n",
    "\n",
    "# First level\n",
    "approximation1, detail1 = pywt.dwt(signal, 'db1')\n",
    "\n",
    "# Second level\n",
    "approximation2, detail2 = pywt.dwt(approximation1, 'db1')\n",
    "\n",
    "'''\n",
    "Note that most libraries provide \"already made\" multi-level decompositions.\n",
    "For example, in Python (pywt), you could use:\n",
    "\n",
    "pywt.wavedec(signal, 'db1', level=2)\n",
    "\n",
    "to perform the two steps done separately (for clarity purposes) in this cell.\n",
    "'''\n",
    "\n",
    "# Visualizing:\n",
    "# First level\n",
    "fig, axes = plt.subplots(3,1, figsize=(10, 6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.plot(signal, c='tab:red')\n",
    "ax0.set_ylabel('Original signal')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.plot(approximation1, c='tab:blue')\n",
    "ax1.set_ylabel('Approximation - lvl 1')\n",
    "\n",
    "ax2 = axes[2]\n",
    "ax2.plot(detail1, c='tab:green')\n",
    "ax2.set_ylabel('Detail - lvl 1')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(ls=':', color='gray', alpha=0.5)\n",
    "plt.suptitle('First level', weight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Second level\n",
    "fig, axes = plt.subplots(3,1, figsize=(10, 6))\n",
    "\n",
    "ax0 = axes[0]\n",
    "ax0.plot(approximation1, c='tab:orange')\n",
    "ax0.set_ylabel('Approximation - lvl 1')\n",
    "\n",
    "ax1 = axes[1]\n",
    "ax1.plot(approximation2, c='tab:blue')\n",
    "ax1.set_ylabel('Approximation - lvl 2')\n",
    "\n",
    "ax2 = axes[2]\n",
    "ax2.plot(detail2, c='tab:green')\n",
    "ax2.set_ylabel('Detail - lvl 2')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(ls=':', color='gray', alpha=0.5)\n",
    "plt.suptitle('Second level - using \"Approximation lvl.1\" as input', weight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example displayed above the red signal is the original signal.\n",
    "The two-step procedure followed is:\n",
    "- This signal is low-pass filtered with the scaling function to give the approximation coefficients at level 1 (blue curve) and high-pass filtered with the wavelet function to give the details coefficients at level 1 (green curve). **The approximation coefficients represents the low-frequency components and the details coefficients the high frequency components**. This is visible in the top three panels.\n",
    "- The new level of the wavelet transform is computed, this time it is not the original signal but from the approximation coefficients of the previous level (level one, in orange). This gives a new set of approximation coefficients (blue curve) and detail coefficients (green curve) shown in the bottom three panels.\n",
    "\n",
    "\n",
    "You can notice that the green curve in the top panel is more noisy than the green curve on the bottom one.\n",
    "That is because the details at level 2 were obtained by high-pass filtering the approximation signal at level 1, which has less high-frequency components than the original signal.\n",
    "This procedure can be repeated over and over to extend the transform to further levels.\n",
    "\n",
    "Generally the approximation coefficients at intermediate levels are not stored, which means that for a transform of level N , the final output will be N signals of detail coefficients (at levels 1 to N ) and one signal of approximation coefficients (at level N ).\n",
    "\n",
    "Note that there is a linear relation between frequency and wavelet level (the frequency decreases with the level).\n",
    "The detail coefficients of the first level correspond to the highest frequencies of the signal.\n",
    "\n",
    "In 2D the procedure is similar except that the high-pass filtering is done in three directions: horizontal, vertical and diagonal.\n",
    "This means that for a transform of level 1, instead of just one signal of details coefficient and one signal of approximation coefficients as in the 1D case, you will get three images of details coefficients (hor., ver. and diag. directions) and one image of approximation coefficient.\n",
    "\n",
    "The wavelet transform is an invertible process and the original signal or image can be retrieved by applying the inverse wavelet transform, which is simply a mirrored version of the wavelet function, to the approximation and details coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Wavelet compression\n",
    "\n",
    "Compression is one of the most important applications of wavelets. The notion behind compression is based on the concept that the regular signal component can be accurately approximated with only the approximation coefficients and a small fraction of the detail coefficients.\n",
    "In other words, we assume that the wavelet transform, is sparse, i.e. a large number of details coefficients are very small (as they correspond to frequencies that are mostly absent from the image) and can be removed without much loss of information.\n",
    "\n",
    "Compression is done in the following way:\n",
    "- Decompose: Choose a wavelet and a decomposition level N . Compute the wavelet decomposition of the signal at level N .\n",
    "- Threshold detail coefficients: for each decomposition level from 1 to N, a threshold is selected and hard thresholding is applied to the detail coefficients.\n",
    "- Reconstruct: Compute inverse wavelet transform by using the original approximation coefficients of level N and the modified detail coefficients of levels from 1 to N.\n",
    "\n",
    "We will now look at a practical example: run the following cell to load the aerial image (in grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the of the aerial image\n",
    "aer_img = np.array(PIL.Image.open(\"2_Wavelets/img.png\"))\n",
    "print('Image size in pixel: ', aer_img.shape)\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.1 # m\n",
    "\n",
    "# Computing x and y coordinates in meters\n",
    "dim_x = aer_img.shape[1]\n",
    "dim_y = aer_img.shape[0]\n",
    "new_x = np.arange(0, dim_x) * pix_res\n",
    "new_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Displaying the image\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.set_aspect('equal')\n",
    "mappable = ax.pcolormesh(new_x, new_y, aer_img, cmap='gray', shading='auto')\n",
    "ax.invert_yaxis()\n",
    "plt.sca(ax)\n",
    "plt.colorbar(mappable=mappable, label='Pixel Intensity')\n",
    "ax.set_xlabel('Distance [m]')\n",
    "ax.set_ylabel('Distance [m]')User avatar\n",
    "level 2\n",
    "Super_Treacle\n",
    "Op ·\n",
    "4h\n",
    "HelpfulWholesomeSilverHugz3\n",
    "\n",
    "󠇃\n",
    "ax.set_title('Original aerial image')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the following cell to perform the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image shape\n",
    "shape = aer_img.shape\n",
    "\n",
    "# how many levels of decomposition to draw\n",
    "max_lev = 2\n",
    "\n",
    "# how many levels to explicitly label on the plots\n",
    "label_levels = max_lev\n",
    "\n",
    "# Choosing a colormap (to see details better even though the image is still in \"black and white\")\n",
    "cmap = plt.cm.magma\n",
    "\n",
    "fig, axes = plt.subplots(2, max_lev+1, figsize=[14, 9])\n",
    "for level in range(0, max_lev + 1):\n",
    "    if level == 0:\n",
    "        # show the original image before decomposition\n",
    "        axes[0, 0].set_axis_off()\n",
    "        axes[1, 0].imshow(aer_img, cmap=cmap)\n",
    "        axes[1, 0].set_title('Original image')\n",
    "        axes[1, 0].set_axis_off()\n",
    "        continue\n",
    "\n",
    "    # plot subband boundaries of a standard DWT basis\n",
    "    draw_2d_wp_basis(shape, wavedec2_keys(level), ax=axes[0, level],\n",
    "                     label_levels=label_levels)\n",
    "    axes[0, level].set_title('{} level\\ndecomposition'.format(level))\n",
    "\n",
    "    # compute the 2D DWT\n",
    "    c = pywt.wavedec2(aer_img, 'db1', mode='periodization', level=level)\n",
    "    \n",
    "    # normalize/increase each coefficient array independently for better visibility\n",
    "    c[0] /= np.abs(c[0]).max()\n",
    "    for detail_level in range(level):\n",
    "        enhanced_d_list = []\n",
    "        for d in c[detail_level + 1]:\n",
    "            nomr_d = d/np.abs(d).max()\n",
    "            increased_d = 20. * nomr_d\n",
    "            increased_d[increased_d > 1] = 1\n",
    "            increased_d[increased_d < -1] = -1\n",
    "            enhanced_d_list.append(increased_d)\n",
    "        c[detail_level + 1] = enhanced_d_list\n",
    "        \n",
    "    # show the normalized coefficients\n",
    "    arr, slices = pywt.coeffs_to_array(c)\n",
    "    \n",
    "    axes[1, level].imshow(arr, cmap=cmap)\n",
    "    axes[1, level].set_title('Coefficients\\n({} level)'.format(level))\n",
    "    axes[1, level].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plots produced by the previous cell, the top row indicates the coefficient names: **v** correspond to vertical details, **h** to horizontal details and **d** to diagonal details.\n",
    "Note that for subsequent levels of decomposition (level 2 onwards), only the approximation coefficients (the lowpass subband) are further decomposed, from there the **a** label in the top-left quadrant.\n",
    "\n",
    "Take a look at the different decompositions and answer the following question:\n",
    "\n",
    "> **Question 9**: Different details of the original image correspond to different contours in the coefficient panels. Provide at least one feature of the original image whose signal is clearly visible in the *horizontal* component, but almost absent in the vertical one. Identify a second feature in the original image whose signal is clearly visible in the *vertical* component, but less marked in the horizontal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Wavelet denoising\n",
    "Every recorded signal is contaminated with noise and remote sensing data makes no exception.\n",
    "The goal of image denoising is to remove noise as much as possible while preserving the features of the image.\n",
    "The multi-resolution analysis performed by the wavelet transform is a very powerful technique to reach this goal.\n",
    "In the wavelet domain, most image information is contained in the largest wavelet coefficients, while the noise is uniformly spread out across all coefficients (since the noise often has an almost uniform signature in the frequency domain).\n",
    "\n",
    "As in wavelet compression, the usual approach to wavelet denoising consists in thresholding the wavelet (detail) coefficients. The thresholds are generally chosen using different estimators that rely on the estimation of the noise variance.\n",
    "Two approaches exist:\n",
    "- **Hard thresholding**, which can be described as the usual process of setting to zero the elements whose absolute values are lower than the threshold;\n",
    "- **Soft thresholding**, which is an extension of hard thresholding, first setting to zero the elements whose absolute values are lower than the threshold, and then shrinking the nonzero coefficients towards 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display;\n",
    "display(Image(filename='2_Wavelets/hard_and_soft_thresholding.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice we will study the performance of wavelet denoising on three types of noise.\n",
    "\n",
    "- **Gaussian white noise**: Gaussian white noise is noise generated by a gaussian distribution with zero mean and a given variance (which can be related to the intensity of the noise).\n",
    "- **Speckle noise**: Speckle noise is an additive noise, i.e. its intensity is proportional on the intensity of the signal. It is inherently associated with active radar. Speckle is a granular ’noise’ that inherently exists in and degrades the quality of the active radar, synthetic aperture radar (SAR), and medical ultrasound images and is caused by interference of reflected electromagnetic waves by a rough surface.\n",
    "- **Salt and pepper noise**: Salt and pepper noise is a form of noise caused by malfunctioning pixels in camera sensors, faulty memory locations in hardware or noisy transmissions. In the corrupted image, noisy pixels can take only the maximum or the minimum value.\n",
    "\n",
    "Let's generate artificially some noise to apply to the aereal image that we analyzed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-loading the of the aerial image\n",
    "aer_img = np.array(PIL.Image.open(\"2_Wavelets/img.png\"))/(2.**16) # between 0 and 1\n",
    "\n",
    "#  Resolution of a pixel\n",
    "pix_res = 0.4 # m\n",
    "\n",
    "# Axis in mIndeed, the image is\n",
    "very corrupted and by eye it is difficult to identify smaller features.\n",
    "dim_x = aer_img.shape[1]\n",
    "dim_y = aer_img.shape[0]\n",
    "new_x = np.arange(0, dim_x) * pix_res\n",
    "new_y = np.arange(0, dim_y) * pix_res\n",
    "\n",
    "# Gaussian noise\n",
    "gaussian_var = 0.01 # Variance of noise\n",
    "aer_img_gaussian = skimage.util.random_noise(aer_img, mode='gaussian', seed=1234, var=gaussian_var)\n",
    "\n",
    "# Speckle noise\n",
    "speckle_var = 0.15  # Variance of noise\n",
    "aer_img_speckle = skimage.util.random_noise(aer_img, mode='speckle', seed=1234, var=speckle_var)\n",
    "\n",
    "# Salt & Pepper noise\n",
    "sp_density = 0.02 # Proportion of image pixels to replace with noise \n",
    "aer_img_sp = skimage.util.random_noise(aer_img, mode='s&p', seed=1234, amount=sp_density)\n",
    "\n",
    "# Visualizing all images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "ax0 = axes[0, 0]\n",
    "mappable = ax0.pcolormesh(new_x, new_y, aer_img, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_title('Original')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "\n",
    "ax1 = axes[0, 1]\n",
    "mappable = ax1.pcolormesh(new_x, new_y, aer_img_gaussian, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_title('Gaussian noise')\n",
    "\n",
    "ax2 = axes[1, 0]\n",
    "mappable = ax2.pcolormesh(new_x, new_y, aer_img_speckle, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax2)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('Speckle noise')\n",
    "ax2.set_xlabel('Distance [m]')\n",
    "ax2.set_ylabel('Distance [m]')\n",
    "\n",
    "ax3 = axes[1, 1]\n",
    "mappable = ax3.pcolormesh(new_x, new_y, aer_img_sp, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax3)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('Salt and pepper noise')\n",
    "ax3.set_xlabel('Distance [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus firts on the image with the superimposed Gaussian noise.\n",
    "Indeed, the image is very corrupted and by eye it is difficult to identify smaller features.\n",
    "\n",
    "Try to perform the de-noising by running the following code cell.\n",
    "The procedure starts by estimating the standard deviation of the Gaussian noise.\n",
    "Once the estimate is ready, we can apply both the hard and soft thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the \"sigma\" of the Gaussian noise\n",
    "sigma_est = skimage.restoration.estimate_sigma(aer_img_gaussian, multichannel=False)\n",
    "print('Estimated sigma of Gaussian noise: ', sigma_est)\n",
    "print('(True sigma: ', np.sqrt(gaussian_var), ')')\n",
    "\n",
    "# Soft thresholding\n",
    "denoised_soft_img_gaussian = skimage.restoration.denoise_wavelet(aer_img_gaussian,\n",
    "                                                                 sigma=sigma_est,\n",
    "                                                                 wavelet='db4',\n",
    "                                                                 mode='soft',\n",
    "                                                                 multichannel=False,\n",
    "                                                                 rescale_sigma=True)\n",
    "# Hard thresholding\n",
    "denoised_hard_img_gaussian = skimage.restoration.denoise_wavelet(aer_img_gaussian,\n",
    "                                                                 sigma=sigma_est,\n",
    "                                                                 wavelet='db4',\n",
    "                                                                 mode='hard',\n",
    "                                                                 multichannel=False,\n",
    "                                                                 rescale_sigma=True)\n",
    "\n",
    "# Visualizing results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "ax0 = axes[0, 0]\n",
    "mappable = ax0.pcolormesh(new_x, new_y, aer_img, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_title('Original')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "\n",
    "ax1 = axes[0, 1]\n",
    "mappable = ax1.pcolormesh(new_x, new_y, aer_img_gaussian, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_title('Gaussian noise')\n",
    "\n",
    "ax2 = axes[1, 0]\n",
    "mappable = ax2.pcolormesh(new_x, new_y, denoised_soft_img_gaussian, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax2)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('Denoised - soft')\n",
    "ax2.set_xlabel('Distance [m]')\n",
    "ax2.set_ylabel('Distance [m]')\n",
    "\n",
    "ax3 = axes[1, 1]\n",
    "mappable = ax3.pcolormesh(new_x, new_y, denoised_hard_img_gaussian, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax3)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('Denoised - hard')\n",
    "ax3.set_xlabel('Distance [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually compare the denoising results with the original image.\n",
    "\n",
    "> **Question 10**: What are the improvement and drawbacks visible in the results? What differences do you observe between the results of the *hard* and *soft* thresholding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat the procedure on the image to which we previously applied the *speckle* noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the \"sigma\" of the equivalent Gaussian noise\n",
    "sigma_est = skimage.restoration.estimate_sigma(aer_img_speckle, multichannel=False)\n",
    "print('Estimated sigma of equivalent Gaussian noise: ', sigma_est)\n",
    "print('(True sigma of the speckle noise: ', np.sqrt(speckle_var), ')')\n",
    "\n",
    "# Soft thresholding\n",
    "denoised_soft_img_speckle = skimage.restoration.denoise_wavelet(aer_img_speckle,\n",
    "                                                                 sigma=sigma_est,\n",
    "                                                                 wavelet='db4',\n",
    "                                                                 mode='soft',\n",
    "                                                                 multichannel=False,\n",
    "                                                                 rescale_sigma=True)\n",
    "# Hard thresholding\n",
    "denoised_hard_img_speckle = skimage.restoration.denoise_wavelet(aer_img_speckle,\n",
    "                                                                 sigma=sigma_est,\n",
    "                                                                 wavelet='db4',\n",
    "                                                                 mode='hard',\n",
    "                                                                 multichannel=False,\n",
    "                                                                 rescale_sigma=True)\n",
    "\n",
    "# Visualizing results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "ax0 = axes[0, 0]\n",
    "mappable = ax0.pcolormesh(new_x, new_y, aer_img, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax0)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_title('Original')\n",
    "ax0.set_ylabel('Distance [m]')\n",
    "\n",
    "ax1 = axes[0, 1]\n",
    "mappable = ax1.pcolormesh(new_x, new_y, aer_img_speckle, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax1)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_title('Speckle noise')\n",
    "\n",
    "ax2 = axes[1, 0]\n",
    "mappable = ax2.pcolormesh(new_x, new_y, denoised_soft_img_speckle, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax2)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('Denoised - soft')\n",
    "ax2.set_xlabel('Distance [m]')\n",
    "ax2.set_ylabel('Distance [m]')\n",
    "\n",
    "ax3 = axes[1, 1]\n",
    "mappable = ax3.pcolormesh(new_x, new_y, denoised_hard_img_speckle, cmap='gray', shading='auto', vmin=0., vmax=1.)\n",
    "plt.sca(ax3)\n",
    "plt.colorbar(mappable=mappable, label='Pixel intensity')\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('Denoised - hard')\n",
    "ax3.set_xlabel('Distance [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the denoising results for the *speckle noise* case.\n",
    "\n",
    "> **Question 11**: Does the denoising perform in this case equally well as in the Gaussian case? Do you see differences in the performances of the soft and hard thresholding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "To conclude the exercise, we propose a task that requires a more direct intervention on the code.\n",
    "\n",
    "> **Question 12 (bonus)**: Taking inspiration from the two denoising code cells presented before, try to apply the same denoising to the image containing salt and pepper. Discuss the performances of the denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
